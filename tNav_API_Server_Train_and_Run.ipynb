{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define image size\n",
    "IMG_SIZE = (224, 224)  # MobileNetV2 requires 224x224 input size\n",
    "\n",
    "# Function to load and preprocess image\n",
    "def load_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)  # Use MobileNetV2 preprocessing\n",
    "    return img_array\n",
    "\n",
    "# Load and preprocess all images from a directory\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        if os.path.isfile(img_path):\n",
    "            img_array = load_image(img_path)\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "    return np.vstack(images), np.array(labels)\n",
    "\n",
    "# Load positive samples (hand sign images)\n",
    "positive_folder = 'path'\n",
    "positive_images, positive_labels = load_images_from_folder(positive_folder, 1)\n",
    "\n",
    "# Load negative samples (non-hand sign images)\n",
    "negative_folder = 'path'\n",
    "negative_images, negative_labels = load_images_from_folder(negative_folder, 0)\n",
    "\n",
    "# Combine and balance data\n",
    "images = np.vstack((positive_images, negative_images))\n",
    "labels = np.concatenate((positive_labels, negative_labels))\n",
    "\n",
    "# Shuffle and split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load the MobileNetV2 model, excluding the top layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom top layers\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(datagen.flow(X_train, y_train, batch_size=32), validation_data=(X_val, y_val), epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import time\n",
    "import threading\n",
    "import tNavigator_python_API as tnav\n",
    "from tNavigator_python_API import ProjectType\n",
    "\n",
    "# Function to preprocess the frame\n",
    "def preprocess_frame(frame):\n",
    "    img = cv2.resize(frame, (224, 224))  # Resize to 224x224 for MobileNetV2\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)  # Use MobileNetV2 preprocessing\n",
    "    return img_array\n",
    "\n",
    "# Function to predict hand sign\n",
    "def predict_hand_sign(model, frame):\n",
    "    img = preprocess_frame(frame)\n",
    "    prediction = model.predict(img)\n",
    "    print(f\"Prediction: {prediction[0][0]}\")  # Debug: print the prediction value\n",
    "    return prediction[0][0] > 0.5  # Return True if the prediction is above 0.5\n",
    "\n",
    "# Function to draw bounding box and text\n",
    "def draw_box_and_text(frame, text, color):\n",
    "    h, w, _ = frame.shape\n",
    "    cv2.rectangle(frame, (int(w*0.1), int(h*0.1)), (int(w*0.9), int(h*0.9)), color, 2)\n",
    "    cv2.putText(frame, text, (int(w*0.3), int(h*0.9) + 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "# Function to execute the given script\n",
    "def execute_script():\n",
    "    conn = tnav.Connection(path_to_exe='path')\n",
    "    snp_project = conn.open_project(path='path')\n",
    "    snp_project.run_py_code(code=\"path')\")\n",
    "    snp_project.run_py_code(file=\"path\")\n",
    "\n",
    "# Function to run the script in a separate thread\n",
    "def run_script_thread():\n",
    "    script_thread = threading.Thread(target=execute_script)\n",
    "    script_thread.start()\n",
    "\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "start_time = None\n",
    "done_duration = 1  # Duration in seconds to hold \"Done\" state\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture image.\")\n",
    "        break\n",
    "    \n",
    "    # Predict hand sign\n",
    "    is_sign_detected = predict_hand_sign(model, frame)\n",
    "    if is_sign_detected:\n",
    "        draw_box_and_text(frame, \"Model_Is_Running_Now_:)\", (0, 255, 0))  # Green box\n",
    "        if start_time is None:\n",
    "            start_time = time.time()\n",
    "        elif time.time() - start_time >= done_duration:\n",
    "            run_script_thread()\n",
    "            break\n",
    "    else:\n",
    "        draw_box_and_text(frame, \"Waiting_For_Ur_Permission\", (0, 0, 255))  # Red box\n",
    "        start_time = None\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Hand Sign Detection', frame)\n",
    "    \n",
    "    # Exit on pressing 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
